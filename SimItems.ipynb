{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michelecoaro/SimItems/blob/main/SimItems.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e290cb42",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e290cb42",
        "outputId": "758496ec-5776-49e8-e945-6bae2ccfb504"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dataproc-spark-connect 0.8.2 requires pyspark[connect]~=3.5.1, but you have pyspark 3.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting cloudpickle==2.2.1\n",
            "  Downloading cloudpickle-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: cloudpickle\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 3.1.1\n",
            "    Uninstalling cloudpickle-3.1.1:\n",
            "      Successfully uninstalled cloudpickle-3.1.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "distributed 2024.12.1 requires cloudpickle>=3.0.0, but you have cloudpickle 2.2.1 which is incompatible.\n",
            "dask 2024.12.1 requires cloudpickle>=3.0.0, but you have cloudpickle 2.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cloudpickle-2.2.1\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "installing libraries that are lacking in colab, only run this the first time\n",
        "'''\n",
        "%pip install --quiet pyspark==3.3.2 kaggle nltk pandas matplotlib\n",
        "!pip install cloudpickle==2.2.1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "dab191c7",
      "metadata": {
        "id": "dab191c7"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Imports\n",
        "'''\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import subprocess\n",
        "import sys\n",
        "import pyspark\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import IntegerType\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, HashingTF, MinHashLSH\n",
        "from pyspark.sql.functions import col, size\n",
        "from pyspark.ml.functions import vector_to_array\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ff54e8a9",
      "metadata": {
        "id": "ff54e8a9"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Starting the project off by defining all the constants, credentials and parameters that will be used throughout the notebook.\n",
        "\n",
        "'''\n",
        "DATA_DIR = Path(\"./data\")\n",
        "DATA_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "KAGGLE_USERNAME = \"XXXXXXXXXXXXX\" #\"Insert your username here\"\n",
        "KAGGLE_KEY = \"XXXXXXXXXXXXX\" #\"Insert your key here\"\n",
        "\n",
        "SUBSAMPLE = True\n",
        "N_SAMPLE = 3000 #500000 is the amount used to replicate the results portrayed in the report, dropped to 3000 due to Colab lack of resources\n",
        "\n",
        "HASH_BUCKETS = 2**20\n",
        "LSH_TABLES = 5\n",
        "JACCARD_THRESHOLD = 0.2\n",
        "RANDOM_SEED = 42\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8a783f19",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a783f19",
        "outputId": "1929d041-41ee-4e4a-c34c-91a1035d3cf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in ./data:\n",
            " • books_data.csv\n",
            " • Books_rating.csv\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Downloading the dataset, ensuring that possible errors are handled.\n",
        "Installing Kaggle if it is missing.\n",
        "Cleaning data directory in case a bad download happened\n",
        "Finally veryfiyng CSV presence\n",
        "'''\n",
        "\n",
        "os.environ[\"KAGGLE_USERNAME\"] = KAGGLE_USERNAME\n",
        "os.environ[\"KAGGLE_KEY\"] = KAGGLE_KEY\n",
        "\n",
        "try:\n",
        "    import kaggle\n",
        "except ImportError:\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"kaggle\"])\n",
        "    import kaggle\n",
        "\n",
        "dataset_slug = \"mohamedbakhet/amazon-books-reviews\"\n",
        "\n",
        "bad_zip = DATA_DIR / \"amazon-books-reviews.zip\"\n",
        "if bad_zip.exists():\n",
        "    bad_zip.unlink()\n",
        "\n",
        "subprocess.check_call(\n",
        "    [\n",
        "        \"kaggle\", \"datasets\", \"download\",\n",
        "        \"-d\", dataset_slug,\n",
        "        \"-p\", str(DATA_DIR),\n",
        "        \"--unzip\",\n",
        "        \"--force\",\n",
        "        \"--quiet\",\n",
        "    ]\n",
        ")\n",
        "\n",
        "csv_files = list(DATA_DIR.glob(\"*.csv\"))\n",
        "if not csv_files:\n",
        "    raise FileNotFoundError(\"Download finished but no CSV files were found in ./data.\")\n",
        "\n",
        "print(\"Files in ./data:\")\n",
        "for p in csv_files:\n",
        "    print(\" •\", p.name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "fb33d068",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb33d068",
        "outputId": "48a43d4e-ebdb-47c2-8656-951fe1e2da56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark version: 3.3.2\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Creating or retrieveing a functioning Spark session\n",
        "'''\n",
        "\n",
        "spark = (\n",
        "    SparkSession.builder\n",
        "    .appName(\"AmazonReviewSimilarity\")\n",
        "    .getOrCreate()\n",
        ")\n",
        "\n",
        "print(\"Spark version:\", spark.version)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "dd8da204",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd8da204",
        "outputId": "01810522-803b-4067-a70e-6d5079e3cd16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Books_rating.csv\n",
            "Total rows (incl. null text): 3000000\n",
            "Working set size: 3000\n",
            "+----------+----------------------------------------------------------------------------------------------------+\n",
            "| review_id|                                                                                         review_text|\n",
            "+----------+----------------------------------------------------------------------------------------------------+\n",
            "|1882931173|This is only for Julie Strain fans. It's a collection of her photos -- about 80 pages worth with ...|\n",
            "|0826414346|I don't care much for Dr. Seuss but after reading Philip Nel's book I changed my mind--that's a g...|\n",
            "|0826414346|                       \"If people become the books they read and if \"\"the child is father to the man|\n",
            "|0826414346|Theodore Seuss Geisel (1904-1991), aka &quot;Dr. Seuss,&quot; was one of the most influential wri...|\n",
            "|0826414346|\"Philip Nel - Dr. Seuss: American IconThis is basically an academic overview of Seuss poetry, art...|\n",
            "+----------+----------------------------------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Loading and preprocessing the dataset, by renaming columns and filtering out invalid reviews. Finishing with subsampling if requested.\n",
        "'''\n",
        "\n",
        "\n",
        "csv_path = Path(\"./data/Books_rating.csv\")\n",
        "if not csv_path.exists():\n",
        "    raise FileNotFoundError(\n",
        "        f\"{csv_path} not found.\\n\"\n",
        "        f\"CSV files in ./data: {[p.name for p in Path('./data').glob('*.csv')]}\"\n",
        "    )\n",
        "\n",
        "print(\"Loading\", csv_path.name)\n",
        "\n",
        "raw_df = (\n",
        "    spark.read\n",
        "    .option(\"header\", \"true\")\n",
        "    .option(\"inferSchema\", \"true\")\n",
        "    .csv(str(csv_path))\n",
        ")\n",
        "\n",
        "print(\"Total rows (incl. null text):\", raw_df.count())\n",
        "\n",
        "rename_map = {\n",
        "    \"review/text\": \"review_text\",\n",
        "    \"review/summary\": \"review_summary\",\n",
        "}\n",
        "for old, new in rename_map.items():\n",
        "    if old in raw_df.columns:\n",
        "        raw_df = raw_df.withColumnRenamed(old, new)\n",
        "\n",
        "df = (\n",
        "    raw_df\n",
        "    .filter(F.col(\"review_text\").isNotNull() & (F.length(\"review_text\") > 0))\n",
        "    .select(\n",
        "        F.col(\"Id\").cast(\"string\").alias(\"review_id\"),\n",
        "        \"review_text\"\n",
        "    )\n",
        ")\n",
        "\n",
        "if SUBSAMPLE:\n",
        "    df = df.sample(False, 1.0, seed=RANDOM_SEED).limit(N_SAMPLE)\n",
        "\n",
        "print(\"Working set size:\", df.count())\n",
        "df.show(5, truncate=100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "27769803",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27769803",
        "outputId": "9c311e16-71d1-4c55-d539-b9838da91de0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows kept after removing zero‐vectors: 3000\n",
            "+----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|review_id |features                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
            "+----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|1882931173|(1048576,[51247,116581,152886,190256,201440,217680,263941,274668,277878,283967,333142,400707,404383,406129,411065,470402,474990,537114,590354,591850,603985,616166,625273,634366,660568,672963,687288,709145,745416,746385,790452,808049,808778,845749,889809,910372,916378,956962,975545,1021807],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
            "|0826414346|(1048576,[17291,30899,30905,32344,34971,49250,76764,80977,82369,100466,102909,109156,111823,141167,168828,170806,199169,202694,206426,209266,213593,213853,219188,234706,267573,280328,283967,286587,305900,316077,330372,336462,341040,356331,383661,390290,391566,393068,398635,415668,430491,437032,437557,448737,451878,452314,452566,458983,461243,469256,470402,487053,487141,496111,502088,524014,531309,532266,549744,586346,592238,595502,607429,614121,621453,622874,637035,641070,651168,665651,687151,694976,698434,705638,711213,714431,729589,744167,747902,759505,774143,796213,819415,820775,824176,842071,843430,848013,858155,859774,871473,879485,886653,895662,895906,899864,900154,909399,915940,924009,936884,937796,939731,968265,971206,975545,985247,987979,990849,997863,1000642,1016076,1018756,1020632,1023809,1035331],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|\n",
            "|0826414346|(1048576,[171368,315714,371897,422028,447703,593235,808002],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
            "+----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Defining the pipeline\n",
        "'''\n",
        "tokenizer = RegexTokenizer(\n",
        "    inputCol=\"review_text\",\n",
        "    outputCol=\"tokens\",\n",
        "    pattern=\"\\\\W+\"\n",
        ")\n",
        "remover = StopWordsRemover(\n",
        "    inputCol=\"tokens\",\n",
        "    outputCol=\"filtered_tokens\"\n",
        ")\n",
        "tf = HashingTF(\n",
        "    inputCol=\"filtered_tokens\",\n",
        "    outputCol=\"features\",\n",
        "    numFeatures=HASH_BUCKETS,\n",
        "    binary=True\n",
        ")\n",
        "lsh = MinHashLSH(\n",
        "    inputCol=\"features\",\n",
        "    outputCol=\"hashes\",\n",
        "    numHashTables=LSH_TABLES\n",
        ")\n",
        "\n",
        "pipeline = Pipeline(stages=[tokenizer, remover, tf, lsh])\n",
        "\n",
        "\n",
        "model = pipeline.fit(df)\n",
        "tmp = model.transform(df).select(\"review_id\", \"features\")\n",
        "\n",
        "\n",
        "df_hashed = (\n",
        "    tmp\n",
        "      .withColumn(\"arr\", vector_to_array(\"features\"))\n",
        "      .filter(  # keep only if any element != 0\n",
        "          F.expr(\"exists(arr, x -> x != 0)\")\n",
        "      )\n",
        "      .drop(\"arr\")\n",
        "      .cache()\n",
        ")\n",
        "\n",
        "print(\"Rows kept after removing zero‐vectors:\", df_hashed.count())\n",
        "df_hashed.show(3, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5dd99aed",
      "metadata": {
        "id": "5dd99aed"
      },
      "source": [
        "Cell 8: Identification of similiar pairs through LSH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "2e84bc82",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e84bc82",
        "outputId": "5970658d-2293-412e-ccc6-c5b7f15366c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Candidate duplicate pairs (distance ≤ 0.2): 0\n",
            "+-----------+-----------+----------------+\n",
            "|review_id_1|review_id_2|jaccard_distance|\n",
            "+-----------+-----------+----------------+\n",
            "+-----------+-----------+----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Identifying similar pairs through LSH\n",
        "'''\n",
        "\n",
        "lsh_model = model.stages[-1]\n",
        "\n",
        "similar_pairs = (\n",
        "    lsh_model.approxSimilarityJoin(\n",
        "        df_hashed, df_hashed, JACCARD_THRESHOLD, distCol=\"jaccard_distance\"\n",
        "    )\n",
        "    .filter(F.col(\"datasetA.review_id\") < F.col(\"datasetB.review_id\"))\n",
        "    .select(\n",
        "        F.col(\"datasetA.review_id\").alias(\"review_id_1\"),\n",
        "        F.col(\"datasetB.review_id\").alias(\"review_id_2\"),\n",
        "        \"jaccard_distance\",\n",
        "    )\n",
        "    .distinct()\n",
        ")\n",
        "\n",
        "print(\n",
        "    f\"Candidate duplicate pairs (distance ≤ {JACCARD_THRESHOLD}): \"\n",
        "    f\"{similar_pairs.count()}\"\n",
        ")\n",
        "similar_pairs.show(10, truncate=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92d0320c",
      "metadata": {
        "id": "92d0320c"
      },
      "source": [
        "Cell 9: Injecting syntethic results into original dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "c983a83d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c983a83d",
        "outputId": "76d2cb61-a0ef-4ff5-ed23-b066b55b52f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Augmented dataset size: 3050\n",
            "Ground-truth duplicate pairs : 50\n",
            "Correctly predicted (TP)      : 50\n",
            "Precision                     : 1.786\n",
            "Recall                        : 1.000\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Injecting duplicates into the original dataset\n",
        "'''\n",
        "dup_source = df.orderBy(F.rand(seed=RANDOM_SEED)).limit(50) #Used 250 for the report\n",
        "duplicated = dup_source.withColumn(\n",
        "    \"review_id\", F.concat(F.lit(\"dup_\"), F.col(\"review_id\"))\n",
        ")\n",
        "df_augmented = df.unionByName(duplicated)\n",
        "print(\"Augmented dataset size:\", df_augmented.count())\n",
        "\n",
        "model_aug = pipeline.fit(df_augmented)\n",
        "\n",
        "df_aug_hashed = (\n",
        "    model_aug\n",
        "      .transform(df_augmented)\n",
        "      .select(\"review_id\", \"features\")\n",
        "      # explode the SparseVector into Array<Double>\n",
        "      .withColumn(\"arr\", vector_to_array(\"features\"))\n",
        "      # keep only rows where at least one entry != 0\n",
        "      .filter(F.expr(\"exists(arr, x -> x != 0)\"))\n",
        "      .drop(\"arr\")\n",
        "      .cache()\n",
        ")\n",
        "\n",
        "aug_lsh_model = model_aug.stages[-1]\n",
        "pred_pairs = (\n",
        "    aug_lsh_model\n",
        "      .approxSimilarityJoin(\n",
        "          df_aug_hashed, df_aug_hashed,\n",
        "          threshold=JACCARD_THRESHOLD,\n",
        "          distCol=\"jaccard_distance\"\n",
        "      )\n",
        "      .filter(F.col(\"datasetA.review_id\") < F.col(\"datasetB.review_id\"))\n",
        "      .select(\n",
        "        F.col(\"datasetA.review_id\").alias(\"id1\"),\n",
        "        F.col(\"datasetB.review_id\").alias(\"id2\")\n",
        "      )\n",
        "      .distinct()\n",
        "      .cache()\n",
        ")\n",
        "\n",
        "truth = dup_source.select(\n",
        "    F.col(\"review_id\").alias(\"id1\"),\n",
        "    F.concat(F.lit(\"dup_\"), F.col(\"review_id\")).alias(\"id2\")\n",
        ")\n",
        "\n",
        "tp        = pred_pairs.join(truth, [\"id1\",\"id2\"]).count()\n",
        "pred_cnt  = pred_pairs.count()\n",
        "truth_cnt = truth.count()\n",
        "\n",
        "precision = tp / pred_cnt if pred_cnt else 0.0\n",
        "recall    = tp / truth_cnt if truth_cnt else 0.0\n",
        "\n",
        "print(f\"Ground-truth duplicate pairs : {truth_cnt}\")\n",
        "print(f\"Correctly predicted (TP)      : {tp}\")\n",
        "print(f\"Precision                     : {precision:.3f}\")\n",
        "print(f\"Recall                        : {recall:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45f2cb30",
      "metadata": {
        "id": "45f2cb30"
      },
      "source": [
        "Cell 10: Examples with duplicate review"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "030aa1c9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "030aa1c9",
        "outputId": "2a071baf-76da-43d1-d48e-52fc564daa3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+----------------+-------------+-------------+\n",
            "|review_id_1|review_id_2|jaccard_distance|review_text_1|review_text_2|\n",
            "+-----------+-----------+----------------+-------------+-------------+\n",
            "+-----------+-----------+----------------+-------------+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Example cell with duplicates\n",
        "'''\n",
        "similar_pairs_with_text = (\n",
        "    similar_pairs\n",
        "    .join(df.select(F.col(\"review_id\").alias(\"review_id_1\"), F.col(\"review_text\").alias(\"review_text_1\")), on=\"review_id_1\")\n",
        "    .join(df.select(F.col(\"review_id\").alias(\"review_id_2\"), F.col(\"review_text\").alias(\"review_text_2\")), on=\"review_id_2\")\n",
        "    .select(\"review_id_1\", \"review_id_2\", \"jaccard_distance\", \"review_text_1\", \"review_text_2\")\n",
        ")\n",
        "\n",
        "similar_pairs_with_text.show(5, truncate=200)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}